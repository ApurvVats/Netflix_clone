{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApurvVats/Netflix_clone/blob/main/Web_Content_Extraction_Analysis_Tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQOCpGDgJ_oA",
        "outputId": "6ac00b63-de14-48c2-9c1d-67a665f8421e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#importing library\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from google.colab import files\n",
        "import csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd5aomXi3oPK",
        "outputId": "d7799101-9f27-49fc-a641-8ef3656926fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/20211030 Test Assignment\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "# drive.mount('/gdrive', force_remount=True)\n",
        "%cd '/gdrive/MyDrive/20211030 Test Assignment'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNxdeqjFKJxf",
        "outputId": "b665de41-6947-4266-9462-0012e4ed0d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9-i7zGZKcNw"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/My Drive/20211030 Test Assignment/Input.xlsx'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOMx0IH7KS5X"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(file_path)[['URL_ID', 'URL']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0axp5xRLEaw"
      },
      "outputs": [],
      "source": [
        "df=df.iloc[0:150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vsBYLdGQLISA",
        "outputId": "501483cd-cb49-4648-a3b0-f8b1fc5d160f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       URL_ID                                                URL\n",
              "0  bctech2011  https://insights.blackcoffer.com/ml-and-ai-bas...\n",
              "1  bctech2012  https://insights.blackcoffer.com/streamlined-i...\n",
              "2  bctech2013  https://insights.blackcoffer.com/efficient-dat...\n",
              "3  bctech2014  https://insights.blackcoffer.com/effective-man...\n",
              "4  bctech2015  https://insights.blackcoffer.com/streamlined-t..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33d73b43-c411-4f75-a7d8-e3e1db2e7ad8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL_ID</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bctech2011</td>\n",
              "      <td>https://insights.blackcoffer.com/ml-and-ai-bas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bctech2012</td>\n",
              "      <td>https://insights.blackcoffer.com/streamlined-i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bctech2013</td>\n",
              "      <td>https://insights.blackcoffer.com/efficient-dat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bctech2014</td>\n",
              "      <td>https://insights.blackcoffer.com/effective-man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bctech2015</td>\n",
              "      <td>https://insights.blackcoffer.com/streamlined-t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33d73b43-c411-4f75-a7d8-e3e1db2e7ad8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33d73b43-c411-4f75-a7d8-e3e1db2e7ad8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33d73b43-c411-4f75-a7d8-e3e1db2e7ad8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a35c169c-2b17-4129-82f9-82ff94dbdb88\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a35c169c-2b17-4129-82f9-82ff94dbdb88')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a35c169c-2b17-4129-82f9-82ff94dbdb88 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 147,\n  \"fields\": [\n    {\n      \"column\": \"URL_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"bctech2136\",\n          \"bctech2062\",\n          \"bctech2149\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"https://insights.blackcoffer.com/lipsync-automation-for-celebrities-and-influencers/\",\n          \"https://insights.blackcoffer.com/an-etl-solution-for-an-internet-publishing-firm/\",\n          \"https://insights.blackcoffer.com/data-etl-local-service-ads-leads-to-bigquery/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IguUrJ9GLoVa"
      },
      "outputs": [],
      "source": [
        "for index, row in df.iterrows():\n",
        "  url = row['URL']\n",
        "  url_id = row['URL_ID']\n",
        "\n",
        "  # make a request to url\n",
        "  header = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"}\n",
        "  try:\n",
        "    response = requests.get(url,headers=header)\n",
        "  except:\n",
        "    print(\"can't get response of {}\".format(url_id))\n",
        "\n",
        "  #create a beautifulsoup object\n",
        "  try:\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "  except:\n",
        "    print(\"can't get page of {}\".format(url_id))\n",
        "  #find title\n",
        "  try:\n",
        "    title = soup.find('h1').get_text()\n",
        "  except:\n",
        "    print(\"can't get title of {}\".format(url_id))\n",
        "    continue\n",
        "  #find text\n",
        "  article = \"\"\n",
        "  try:\n",
        "    for p in soup.find_all('p'):\n",
        "      article += p.get_text()\n",
        "  except:\n",
        "    print(\"can't get text of {}\".format(url_id))\n",
        "\n",
        "  file_name = '/content/drive/MyDrive/20211030 Test Assignment/'+str(url_id)+'.txt'\n",
        "  with open(file_name, 'w') as file:\n",
        "    file.write(title + '\\n' + article)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMOxkzCGSr_B"
      },
      "outputs": [],
      "source": [
        "text_dic = \"/content/drive/MyDrive/20211030 Test Assignment\"\n",
        "stopwords_dir = \"/content/drive/My Drive/20211030 Test Assignment/StopWords\"\n",
        "sentment_dir = \"/content/drive/My Drive/20211030 Test Assignment/MasterDictionary\"\n",
        "\n",
        "stop_words = set()\n",
        "for files in os.listdir(stopwords_dir):\n",
        "  with open(os.path.join(stopwords_dir,files),'r',encoding='ISO-8859-1') as f:\n",
        "    stop_words.update(set(f.read().splitlines()))\n",
        "\n",
        "# load all text files  from the  directory and store in a list(docs)\n",
        "docs = []\n",
        "for text_file in os.listdir(text_dic):\n",
        "  # Check if the file is a text file\n",
        "  if text_file.endswith(\".txt\"):\n",
        "    with open(os.path.join(text_dic,text_file),'r', encoding='ISO-8859-1') as f:\n",
        "      text = f.read()\n",
        "    #tokenize the given text file\n",
        "      words = word_tokenize(text)\n",
        "    # remove the stop words from the tokens\n",
        "      filtered_text = [word for word in words if word.lower() not in stop_words]\n",
        "    # add each filtered tokens of each file into a list\n",
        "      docs.append(filtered_text)\n",
        "\n",
        "#tokenize the given text file\n",
        "    words = word_tokenize(text)\n",
        "# remove the stop words from the tokens\n",
        "    filtered_text = [word for word in words if word.lower() not in stop_words]\n",
        "# add each filtered tokens of each file into a list\n",
        "    docs.append(filtered_text)\n",
        "\n",
        "\n",
        "\n",
        "# store positive, Negative words from the directory\n",
        "pos=set()\n",
        "neg=set()\n",
        "\n",
        "for files in os.listdir(sentment_dir):\n",
        "  if files =='positive-words.txt':\n",
        "    with open(os.path.join(sentment_dir,files),'r',encoding='ISO-8859-1') as f:\n",
        "      pos.update(f.read().splitlines())\n",
        "  else:\n",
        "    with open(os.path.join(sentment_dir,files),'r',encoding='ISO-8859-1') as f:\n",
        "      neg.update(f.read().splitlines())\n",
        "\n",
        "# now collect the positive  and negative words from each file\n",
        "# calculate the scores from the positive and negative words\n",
        "positive_words = []\n",
        "Negative_words =[]\n",
        "positive_score = []\n",
        "negative_score = []\n",
        "polarity_score = []\n",
        "subjectivity_score = []\n",
        "\n",
        "#iterate through the list of docs\n",
        "for i in range(len(docs)):\n",
        "  positive_words.append([word for word in docs[i] if word.lower() in pos])\n",
        "  Negative_words.append([word for word in docs[i] if word.lower() in neg])\n",
        "  positive_score.append(len(positive_words[i]))\n",
        "  negative_score.append(len(Negative_words[i]))\n",
        "  polarity_score.append((positive_score[i] - negative_score[i]) / ((positive_score[i] + negative_score[i]) + 0.000001))\n",
        "  subjectivity_score.append((positive_score[i] + negative_score[i]) / ((len(docs[i])) + 0.000001))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a02ExqKYbSJ",
        "outputId": "507b40d6-17e6-4831-8f57-a700f9c731e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping /content/drive/MyDrive/20211030 Test Assignment/StopWords as it is not a file.\n",
            "Skipping /content/drive/MyDrive/20211030 Test Assignment/MasterDictionary as it is not a file.\n"
          ]
        }
      ],
      "source": [
        "# Average Sentence Length = the number of words / the number of sentences\n",
        "# Percentage of Complex words = the number of complex words / the number of words\n",
        "# Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
        "\n",
        "import os\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Define your lists to store results\n",
        "avg_sentence_length = []\n",
        "Percentage_of_Complex_words = []\n",
        "Fog_Index = []\n",
        "complex_word_count = []\n",
        "avg_syllable_word_count = []\n",
        "\n",
        "# Initialize stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def measure(file):\n",
        "    file_path = os.path.join(text_dic, file)\n",
        "\n",
        "    # Check if it's a file and not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        try:\n",
        "            # Read the file with ISO-8859-1 encoding to avoid decoding errors\n",
        "            with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
        "                text = f.read()\n",
        "\n",
        "            # Remove punctuations\n",
        "            text = re.sub(r'[^\\w\\s.]', '', text)\n",
        "\n",
        "            # Split the text into sentences\n",
        "            sentences = text.split('.')\n",
        "\n",
        "            # Total number of sentences\n",
        "            num_sentences = len(sentences)\n",
        "\n",
        "            # Filter out stop words and count total words\n",
        "            words = [word for word in text.split() if word.lower() not in stop_words]\n",
        "            num_words = len(words)\n",
        "\n",
        "            # Complex words (more than 2 syllables)\n",
        "            complex_words = []\n",
        "            vowels = 'aeiou'\n",
        "            for word in words:\n",
        "                syllable_count_word = sum(1 for letter in word if letter.lower() in vowels)\n",
        "                if syllable_count_word > 2:\n",
        "                    complex_words.append(word)\n",
        "\n",
        "            # Syllable count per word\n",
        "            syllable_count = 0\n",
        "            syllable_words = []\n",
        "            for word in words:\n",
        "                if word.endswith('es'):\n",
        "                    word = word[:-2]\n",
        "                elif word.endswith('ed'):\n",
        "                    word = word[:-2]\n",
        "                syllable_count_word = sum(1 for letter in word if letter.lower() in vowels)\n",
        "                if syllable_count_word >= 1:\n",
        "                    syllable_words.append(word)\n",
        "                    syllable_count += syllable_count_word\n",
        "\n",
        "            # Calculate metrics\n",
        "            avg_sentence_len = num_words / num_sentences if num_sentences > 0 else 0\n",
        "            avg_syllable_word_count = syllable_count / len(syllable_words) if len(syllable_words) > 0 else 0\n",
        "            Percent_Complex_words = len(complex_words) / num_words if num_words > 0 else 0\n",
        "            Fog_Index = 0.4 * (avg_sentence_len + Percent_Complex_words)\n",
        "\n",
        "            return avg_sentence_len, Percent_Complex_words, Fog_Index, len(complex_words), avg_syllable_word_count\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while reading {file}: {e}\")\n",
        "            return None, None, None, None, None\n",
        "    else:\n",
        "        print(f\"Skipping {file_path} as it is not a file.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "# Iterate through each file in the directory\n",
        "for file in os.listdir(text_dic):\n",
        "    result = measure(file)\n",
        "    if result and all(result):  # Only append if result is valid\n",
        "        x, y, z, a, b = result\n",
        "        avg_sentence_length.append(x)\n",
        "        Percentage_of_Complex_words.append(y)\n",
        "        Fog_Index.append(z)\n",
        "        complex_word_count.append(a)\n",
        "        avg_syllable_word_count.append(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcrZwTVBYb_U",
        "outputId": "d26d86f1-729d-43dc-f212-a91340e5b057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping /content/drive/MyDrive/20211030 Test Assignment/StopWords as it is not a file.\n",
            "Skipping /content/drive/MyDrive/20211030 Test Assignment/MasterDictionary as it is not a file.\n",
            "Word Count: [694, 0, 0, 1071, 504, 527, 634, 205, 205, 206, 206, 203, 206, 206, 212, 206, 209, 514, 401, 294, 506, 453, 444, 543, 487, 516, 566, 294, 402, 350, 415, 541, 650, 326, 293, 259, 193, 245, 302, 388, 308, 242, 300, 269, 391, 308, 388, 292, 312, 343, 385, 377, 304, 226, 213, 279, 289, 336, 230, 345, 390, 271, 360, 374, 250, 208, 220, 228, 214, 251, 326, 364, 376, 412, 371, 335, 601, 316, 354, 192, 329, 316, 222, 256, 303, 360, 192, 250, 316, 340, 283, 201, 243, 295, 252, 237, 272, 605, 628, 190, 311, 246, 313, 280, 353, 278, 333, 214, 310, 165, 500, 337, 338, 234, 313, 336, 428, 312, 356, 192, 255, 224, 360, 309, 160, 203, 213, 202, 193, 189, 316, 232, 381, 275, 348, 306, 324, 312, 231, 230, 219, 225, 224, 207, 210, 278, 711, 517, 705, 1008, 265, 161, 212]\n",
            "Average Word Length: [14.802593659942364, 0, 0, 12.285714285714286, 13.015873015873016, 14.407969639468691, 8.052050473186119, 8.478048780487805, 8.502439024390243, 8.470873786407767, 8.514563106796116, 8.52216748768473, 8.422330097087379, 8.475728155339805, 8.56132075471698, 8.674757281553399, 8.47846889952153, 8.745136186770427, 8.099750623441397, 8.153061224489797, 7.737154150197629, 8.300220750551876, 7.761261261261262, 7.9650092081031305, 8.102669404517453, 7.924418604651163, 8.183745583038869, 7.7687074829931975, 8.64179104477612, 8.274285714285714, 7.7783132530120485, 7.469500924214418, 6.949230769230769, 7.8128834355828225, 7.552901023890785, 8.227799227799228, 8.26943005181347, 7.828571428571428, 7.3509933774834435, 9.512886597938145, 8.064935064935066, 8.409090909090908, 7.8, 7.717472118959108, 7.388746803069053, 7.886363636363637, 7.180412371134021, 7.4965753424657535, 8.637820512820513, 7.3236151603498545, 7.1922077922077925, 7.679045092838196, 7.723684210526316, 8.230088495575222, 8.56338028169014, 6.659498207885305, 7.9342560553633215, 7.315476190476191, 8.004347826086956, 7.736231884057971, 7.430769230769231, 7.952029520295203, 7.502777777777778, 7.7005347593582885, 8.204, 8.163461538461538, 8.186363636363636, 8.140350877192983, 8.345794392523365, 8.250996015936256, 7.846625766871166, 7.96978021978022, 7.4361702127659575, 7.322815533980583, 7.7466307277628035, 7.623880597014925, 7.757071547420965, 7.341772151898734, 7.61864406779661, 8.161458333333334, 7.601823708206687, 7.544303797468355, 8.175675675675675, 7.9140625, 7.33003300330033, 7.2, 8.348958333333334, 8.236, 7.860759493670886, 7.597058823529411, 7.957597173144876, 7.980099502487562, 8.337448559670781, 8.216949152542373, 7.964285714285714, 7.620253164556962, 7.599264705882353, 7.343801652892562, 7.296178343949045, 8.189473684210526, 7.270096463022508, 7.784552845528455, 7.361022364217252, 7.746428571428571, 7.8215297450424925, 7.643884892086331, 7.138138138138138, 8.130841121495328, 7.583870967741936, 8.27878787878788, 7.15, 6.98813056379822, 7.195266272189349, 7.747863247863248, 7.319488817891374, 7.330357142857143, 7.322429906542056, 7.262820512820513, 7.235955056179775, 8.3125, 8.313725490196079, 7.888392857142857, 7.533333333333333, 7.705501618122978, 11.14375, 8.285714285714286, 8.19718309859155, 8.0, 8.373056994818652, 8.343915343915343, 7.598101265822785, 8.530172413793103, 7.440944881889764, 7.64, 7.818965517241379, 7.640522875816994, 7.75, 7.955128205128205, 8.025974025974026, 8.021739130434783, 8.333333333333334, 8.164444444444445, 8.245535714285714, 8.154589371980677, 8.161904761904761, 7.071942446043166, 7.20112517580872, 6.669245647969052, 7.073758865248227, 7.000992063492063, 7.739622641509434, 8.559006211180124, 8.014150943396226]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Ensure nltk stopwords are downloaded\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def cleaned_words(file):\n",
        "    file_path = os.path.join(text_dic, file)\n",
        "\n",
        "    # Check if it's a file before attempting to read it\n",
        "    if os.path.isfile(file_path):\n",
        "        try:\n",
        "            # Open the file with ISO-8859-1 encoding to avoid decoding errors\n",
        "            with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
        "                text = f.read()\n",
        "                # Remove punctuations\n",
        "                text = re.sub(r'[^\\w\\s]', '', text)\n",
        "                # Filter out stopwords\n",
        "                words = [word for word in text.split() if word.lower() not in stop_words]\n",
        "                # Calculate total word length and average word length\n",
        "                length = sum(len(word) for word in words)\n",
        "                average_word_length = length / len(words) if words else 0\n",
        "            return len(words), average_word_length\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing {file}: {e}\")\n",
        "            return 0, 0  # Return 0 if an error occurs\n",
        "    else:\n",
        "        print(f\"Skipping {file_path} as it is not a file.\")\n",
        "        return 0, 0\n",
        "\n",
        "# Initialize lists for storing results\n",
        "word_count = []\n",
        "average_word_length = []\n",
        "\n",
        "# Iterate through each file in the directory\n",
        "for file in os.listdir(text_dic):\n",
        "    x, y = cleaned_words(file)\n",
        "    word_count.append(x)\n",
        "    average_word_length.append(y)\n",
        "\n",
        "# Output the results\n",
        "print(\"Word Count:\", word_count)\n",
        "print(\"Average Word Length:\", average_word_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtQiKN3SYchP",
        "outputId": "bea1f08d-5a84-41d1-d740-aa88db3190c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping /content/drive/MyDrive/20211030 Test Assignment/StopWords as it is not a file.\n",
            "Skipping /content/drive/MyDrive/20211030 Test Assignment/MasterDictionary as it is not a file.\n",
            "Personal Pronoun Counts: [6, 0, 0, 11, 19, 12, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 3, 12, 7, 4, 2, 14, 5, 10, 4, 3, 2, 6, 2, 11, 7, 3, 6, 2, 4, 2, 7, 4, 4, 2, 3, 10, 3, 2, 5, 10, 16, 5, 2, 2, 2, 3, 2, 2, 9, 2, 4, 4, 3, 6, 3, 2, 3, 2, 3, 2, 3, 7, 7, 5, 8, 10, 4, 5, 2, 2, 2, 4, 4, 2, 1, 6, 1, 1, 1, 2, 1, 1, 2, 1, 3, 2, 2, 1, 2, 1, 1, 2, 1, 1, 4, 5, 4, 4, 3, 4, 1, 2, 2, 1, 1, 3, 6, 7, 3, 2, 3, 1, 2, 3, 4, 2, 1, 1, 1, 1, 1, 4, 3, 4, 2, 7, 4, 1, 7, 1, 1, 1, 1, 1, 1, 1, 3, 6, 2, 3, 5, 10, 1, 2]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def count_personal_pronouns(file):\n",
        "    file_path = os.path.join(text_dic, file)\n",
        "\n",
        "    # Check if it's a file before attempting to read it\n",
        "    if os.path.isfile(file_path):\n",
        "        try:\n",
        "            # Open the file with ISO-8859-1 encoding to avoid decoding errors\n",
        "            with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
        "                text = f.read()\n",
        "                # Define personal pronouns\n",
        "                personal_pronouns = [\"I\", \"we\", \"my\", \"ours\", \"us\"]\n",
        "                count = 0\n",
        "                # Count occurrences of each personal pronoun\n",
        "                for pronoun in personal_pronouns:\n",
        "                    count += len(re.findall(r\"\\b\" + re.escape(pronoun) + r\"\\b\", text))\n",
        "            return count\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing {file}: {e}\")\n",
        "            return 0  # Return 0 if an error occurs\n",
        "    else:\n",
        "        print(f\"Skipping {file_path} as it is not a file.\")\n",
        "        return 0\n",
        "\n",
        "# Initialize list for storing results\n",
        "pp_count = []\n",
        "\n",
        "# Iterate through each file in the directory\n",
        "for file in os.listdir(text_dic):\n",
        "    x = count_personal_pronouns(file)\n",
        "    pp_count.append(x)\n",
        "\n",
        "# Output the results\n",
        "print(\"Personal Pronoun Counts:\", pp_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ples6Z3x0jjZ"
      },
      "outputs": [],
      "source": [
        "data={'positive_score':positive_score,'negative_score':negative_score,'Polarity_Score':polarity_score,'subjectivity_score':subjectivity_score,'avg_senetence_length':avg_sentence_length,'Percentage_of_Complex_words':Percentage_of_Complex_words,'Fog_Index':Fog_Index,'avg_no_of_words_per_sentence':avg_sentence_length,'complex_Word_Count':complex_word_count,'word_count':word_count,'syllable_count':avg_syllable_word_count,'personal_pronouns':pp_count,'avg_word_length':average_word_length}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new = pd.DataFrame.from_dict(data)\n",
        "\n",
        "new\n",
        "new.to_csv('file1.csv')"
      ],
      "metadata": {
        "id": "mDC-o6BUSOp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}